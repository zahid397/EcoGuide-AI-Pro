import os
import pandas as pd
from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer
from uuid import uuid4
from dotenv import load_dotenv

# à¦à¦¨à¦­à¦¾à¦¯à¦¼à¦°à¦¨à¦®à§‡à¦¨à§à¦Ÿ à¦²à§‹à¦¡
load_dotenv()

# à¦•à¦¨à¦«à¦¿à¦—à¦¾à¦°à§‡à¦¶à¦¨
QDRANT_URL = os.getenv("QDRANT_URL", ":memory:") # à¦¡à¦¿à¦«à¦²à§à¦Ÿ à¦®à§‡à¦®à§‹à¦°à¦¿ à¦®à§‹à¦¡
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
COLLECTION = "eco_travel_v3"

# à¦ªà¦¾à¦¥ à¦«à¦¿à¦•à§à¦¸ (à¦¯à¦¾à¦¤à§‡ data à¦«à§‹à¦²à§à¦¡à¦¾à¦° à¦–à§à¦à¦œà§‡ à¦ªà¦¾à§Ÿ)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")

print("ğŸš€ Starting Database Setup...")
print(f"ğŸ“‚ Looking for data in: {DATA_DIR}")

# à§§. à¦•à§à¦²à¦¾à§Ÿà§‡à¦¨à§à¦Ÿ à¦•à¦¾à¦¨à§‡à¦•à§à¦Ÿ à¦•à¦°à¦¾
try:
    if QDRANT_URL == ":memory:":
        client = QdrantClient(":memory:")
    else:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
    print("âœ… Connected to Qdrant!")
except Exception as e:
    print(f"âŒ Connection Failed: {e}")
    exit()

# à§¨. à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡ à¦•à¦°à¦¾
print("ğŸ§  Loading Embedding Model (might take a moment)...")
model = SentenceTransformer("all-MiniLM-L6-v2")

# à§©. à¦•à¦¾à¦²à§‡à¦•à¦¶à¦¨ à¦°à¦¿à¦¸à§‡à¦Ÿ à¦•à¦°à¦¾
print("ğŸ—‘ï¸ Clearing old data...")
try:
    client.delete_collection(COLLECTION)
except:
    pass # à¦•à¦¾à¦²à§‡à¦•à¦¶à¦¨ à¦¨à¦¾ à¦¥à¦¾à¦•à¦²à§‡ à¦‡à¦—à¦¨à§‹à¦° à¦•à¦°à§‹

client.recreate_collection(
    collection_name=COLLECTION,
    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)
)
print("âœ¨ New Collection Created!")

# à§ª. à¦¡à¦¾à¦Ÿà¦¾ à¦†à¦ªà¦²à§‹à¦¡ à¦•à¦°à¦¾
files = {
    "Hotel": "hotels.csv",
    "Activity": "activities.csv",
    "Place": "places.csv"
}

total_indexed = 0

for dtype, filename in files.items():
    file_path = os.path.join(DATA_DIR, filename)
    
    if not os.path.exists(file_path):
        print(f"âš ï¸ WARNING: File not found: {filename}")
        continue
        
    df = pd.read_csv(file_path)
    points = []
    
    print(f"ğŸ“„ Indexing {len(df)} {dtype}s from {filename}...")
    
    for _, row in df.iterrows():
        # à¦Ÿà§‡à¦•à§à¦¸à¦Ÿ à¦¤à§ˆà¦°à¦¿ (à¦¯à§‡à¦Ÿà¦¾ à¦¦à¦¿à§Ÿà§‡ à¦¸à¦¾à¦°à§à¦š à¦¹à¦¬à§‡)
        text_data = f"{dtype}: {row.get('name', '')} in {row.get('location', '')}. {row.get('description', '')} Eco Score: {row.get('eco_score', 0)}"
        
        # à¦­à§‡à¦•à§à¦Ÿà¦° à¦œà§‡à¦¨à¦¾à¦°à§‡à¦Ÿ
        embedding = model.encode(text_data).tolist()
        
        # à¦¡à¦¾à¦Ÿà¦¾ à¦°à§‡à¦¡à¦¿ à¦•à¦°à¦¾
        payload = row.to_dict()
        payload['data_type'] = dtype
        # à¦¨à¦¿à¦¶à§à¦šà¦¿à¦¤ à¦•à¦°à¦¾ à¦¯à§‡ à¦«à¦¿à¦²à§à¦¡à¦—à§à¦²à§‹ à¦†à¦›à§‡
        payload.setdefault('eco_score', 5.0)
        payload.setdefault('cost', 0)
        
        points.append(models.PointStruct(
            id=str(uuid4()),
            vector=embedding,
            payload=payload
        ))
    
    if points:
        client.upsert(collection_name=COLLECTION, points=points)
        total_indexed += len(points)

print("\n------------------------------------------------")
if total_indexed > 0:
    print(f"ğŸ‰ SUCCESS! Total {total_indexed} items loaded into database.")
    print("ğŸ‘‰ Now run: streamlit run app.py")
else:
    print("âŒ ERROR: No data loaded. Please check if CSV files exist inside 'data/' folder.")
print("------------------------------------------------")
